{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dele_img = []\n",
    "label_dele =[]\n",
    "for filename in os.listdir(\"Dataset/Training_set/dele\"):\n",
    "    filename = os.path.join(\"Dataset/Training_set/dele\", filename)\n",
    "    img = cv2.imread(filename,1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img =cv2.resize(img, (64,64))\n",
    "    list_dele_img.append(img/float(255))\n",
    "    label_dele.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_olamide_img = []\n",
    "label_olamide =[]\n",
    "for filename in os.listdir(\"Dataset/Training_set/olamide\"):\n",
    "    filename = os.path.join(\"Dataset/Training_set/olamide\", filename)\n",
    "    img = cv2.imread(filename,1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img =cv2.resize(img, (64,64))\n",
    "    list_dele_img.append(img/float(255))\n",
    "    label_olamide.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_itunu_img = []\n",
    "label_itunu =[]\n",
    "for filename in os.listdir(\"Dataset/Training_set/itunu\"):\n",
    "    filename = os.path.join(\"Dataset/Training_set/itunu\", filename)\n",
    "    img = cv2.imread(filename,1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img =cv2.resize(img, (64,64))\n",
    "    list_dele_img.append(img/float(255))\n",
    "    label_itunu.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list_dele_img + list_olamide_img + list_itunu_img\n",
    "label = label_dele  + label_olamide + label_itunu\n",
    "data = np.array(data)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 64, 64, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reshape(data.shape[0],64,64,1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "label = np_utils.to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493, 64, 64, 1) (493, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape,label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,664,995\n",
      "Trainable params: 1,664,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape = (64,64,1), activation = \"relu\"))\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "\n",
    "model.add(MaxPooling2D(3,3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation ='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation ='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(3,activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss ='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2194 - accuracy: 0.4178WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 1.2194 - accuracy: 0.4178\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0359 - accuracy: 0.5172WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 1.0359 - accuracy: 0.5172\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9866 - accuracy: 0.5822WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.9866 - accuracy: 0.5822\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9337 - accuracy: 0.6085WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.9337 - accuracy: 0.6085\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8832 - accuracy: 0.6268WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.8832 - accuracy: 0.6268\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8137 - accuracy: 0.6592WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.8137 - accuracy: 0.6592\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7336 - accuracy: 0.6775WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.7336 - accuracy: 0.6775\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.7079WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.6999 - accuracy: 0.7079\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.7383WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.6334 - accuracy: 0.7383\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5497 - accuracy: 0.8053WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.5497 - accuracy: 0.8053\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8012WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.4813 - accuracy: 0.8012\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8661WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.3983 - accuracy: 0.8661\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.8844WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.3270 - accuracy: 0.8844\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.9270WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.2586 - accuracy: 0.9270\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9432WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.1892 - accuracy: 0.9432\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9635WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.1343 - accuracy: 0.9635\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.9757WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0934 - accuracy: 0.9757\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9899WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0672 - accuracy: 0.9899\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9980WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0417 - accuracy: 0.9980\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9980WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0319 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f645d7e688>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint =ModelCheckpoint(filepath ='CNN.h5', verbose = 0, save_best_only= True)\n",
    "model.fit(data,label, epochs = 20, batch_size = 128, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Image_Recognition.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:\\\\Users\\\\olamide\\\\Desktop\\\\20201025_170408.jpg\"\n",
    "img = cv2.imread(file,1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img =cv2.resize(img, (64,64))\n",
    "img = img/float(255)\n",
    "img = np.array(img)\n",
    "img = img.reshape(1,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11612719, 0.87813824, 0.00573465]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(img)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olamide\n"
     ]
    }
   ],
   "source": [
    "if np.argmax(result) == 0:\n",
    "    print(\"Dele\")\n",
    "elif np.argmax(result) == 1:\n",
    "    print(\"Olamide\")\n",
    "else:\n",
    "    print(\"Itunu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
